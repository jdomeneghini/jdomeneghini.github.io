<!DOCTYPE html><html><head><title>By @jdomeneghini – DATA SCIENCE</title><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no"><link rel="stylesheet" href="/css/main.e67af32c.css"></head><body class="is-preload">  <div id="wrapper"> <header id="header"> <div class="inner"> <h2><a href="/">By @jdomeneghini – DATA SCIENCE</a></h2> <nav> <ul> <li><a href="#menu">Menu</a></li> </ul> </nav> </div> </header> <nav id="menu"> <h2>Menu</h2> <ul> <li><a href="/index.html">Home</a></li> </ul> </nav>  <div id="main"> <div class="inner"> <h1>Avaliação de Risco de Crédito</h1> <span class="image main"></span> <p> Este projeto de Data Science aborda um assunto muito interessante que é a análise de crédito. Através dessa análise as instituições financeiras podem se proteger de alguns riscos, como a inadimplência. Neste desafio, usando um data set disponibilizado pela fintech Nubank, o objetivo é criar um modelo de machine learning capaz de prever e minimizar perdas financeiras da startup. </p> <p> Antes de qualquer utilização das técnicas de inteligência artificial para ajudar na resolução de problemas e automatizar processos, uma etapa bem importante, que demanda tempo e atenção, e que irá ajudar muito na obtenção de um ótimo resultado é a etapa de PRÉ PROCESSAMENTO dos dados, pois é onde iremos preparar, limpar e estruturar os dados para que na hora de trabalhar com eles na criação de um modelo de machine learning por exemplo, gerem resultados de qualidade. <br>Explicando melhor as dimensões deste dataset: </p> <img src="/images/image1.9adfeda9.jpg"> <p> Trata-se de um conjunto de dados grande e com bastantes atributos e nesta preparação dos dados irei enfatizar algumas técnicas utilizadas. </p> <h3> Tratamento de valores ausentes (faltantes) - tipo NaN , com SimpleImputer </h3> <p> Normalmente em um conjunto de dados temos que lidar com valores ausentes, e temos algumas abordagens para resolver este problema, remoção ou imputação. A remoção deve ser considerada em casos onde não haverá impacto na análise e/ou no modelo, pois se muitas informações forem descartadas pode não ser possível concluir uma análise confiável. O método de imputação desenvolve suposições razoáveis para os dados ausentes, quando temos casos com baixo valores ausentes podemos usar a média, moda ou mediana das observações existentes. No entanto, quando temos uma porcentagem alta de valores ausentes podemos usar métodos específicos de série temporal, como tendência ou sazonalidade. Agora analisando o quadro abaixo, podemos ver a quantidade de valores ausentes de cada atributo em % do dataset trabalhado. </p> <img src="/images/image2.a44964ae.png"> <p> Durante a análise identifiquei que devido aos muitos valores nulos, alguns itens não são obrigatórios o preenchimento e em outros não é aplicável o preenchimento. Para estes casos, usarei o método de imputação onde irei substituir os valores do tipo NaN por 0, as variáveis numéricas pelo valor da mediana e as variáveis categóricas para o valor mais frequente. Para fazer estas modificações utilizarei uma ferramenta da biblioteca do SciKit Learn chamada 'SimpleImputer'. </p> <img src="/images/image3.2a64ff63.png"> <p> Com essa ferramenta eu completo todos os meus dados ausentes de forma rápida e eficaz. </p> <h3>Padronização de dados - com StandardScaler</h3> <p> Muitos algoritmos de machine learning funcionam melhor quando os valores dos atributos do tipo numéricos estão em uma escala parecida com uma distribuição normal, isso é feito para evitar que o modelo não fique enviesado. StandardScaler é uma função presente na biblioteca do SKLearn. Essa função irá alterar os valores de modo que o desvio padrão da distribuição da média seja igual a um. A variância é igual a 1 também, porque variância = desvio padrão² (1² = 1). Ele produz algo muito próximo de uma distribuição normal. </p> <img src="/images/image4.cb2230d8.jpg"> <h3>Tratamento de dados categóricos - com LabelEncoder</h3> <p> Um conjunto de dados quase sempre contém texto ou valores categóricos (valores não numéricos) e a maioria dos algoritmos preditivos não alcançam resultados satisfatórios com dados deste form e para que eles possam entender melhor os dados, transformamos eles em tipo numéricos e neste caso usarei o LabelEncoder - também presente na biblioteca do SciKit Learn. </p> <img src="/images/image5.3e5ebf3e.jpg"> <h3>Balanceamento de dados</h3> <p> Dados desbalanceados impactam no treinamento e teste do algoritmo, pois o algoritmo tende a classificar os novos dados como sendo da classe que possui mais exemplos, e para isso existem ferramentas que equalizam estes dados. </p> <img src="/images/image6.0106a680.jpg"> <p> De acordo com este gráfico podemos ver que os dados estão desbalanceados, pois somente 15% dos dados são classificados como TRUE (inadimplentes). Utilizei dois métodos de balanceamento e depois testei com o algoritmo para ver qual se comportou melhor. O primeiro deles foi o SMOTE, ele gera dados sintéticos da classe minoritária a partir de vizinhos. </p> <img src="/images/image7.f253489b.jpg"> <img src="/images/image8.c9ac4a01.jpg"> <p> O segundo método foi utilizado a técnica de UnderSampling, onde ele reduz de forma aleatória os exemplos da classe majoritária. </p> <img src="/images/image9.39e8154f.jpg"> <img src="/images/image10.12f8a5db.jpg"> <h3>CONSTRUÇÃO DO MODELO DE MACHINE LEARNING</h3> Neste projeto em questão vou utilizar o algoritmo XGBoost, ele vem sendo bem utilizado para problemas similares a este. É um algoritmo baseado em árvore de decisão e que utiliza uma estrutura de Gradient Boosting. Eu testei este algoritmo encima dos dados balanceados pelos dois métodos falados acima, para ver qual iria ser melhor treinado. Aqui o resultado entre estes dois modelo criados e as métricas de avaliação consideradas para medir a sua eficácia. Balanceando os dados com SMOTE: <img src="/images/image11.00e054c2.jpg"> <p> Pelas métricas de avaliação o modelo atingiu ótimos resultados. A acurácia foi de 89%. Analisando esta matriz temos: False Positive - 100%/ False Negative - 22% True Positive - 78% / True Negative - 0% Ou seja, das classificações onde eram falsos positivos o modelo acertou praticamente 100%, e falsos negativos o modelo errou em 22%. Balanceando os dados com RandomUnderSampler: </p> <img src="/images/image12.e9976386.jpg"> <p> Por aqui podemos ver que o modelo não se comportou tão bem com o balanceamento efetuado. A acurácia do modelo foi de 64%. Vamos para os resultados da matriz de confusão: False Positive - 69%/ False Negative - 31% True Positive - 59% / True Negative - 41% Ou seja, das classificações onde eram falsos positivos o modelo acertou 66%, e falsos negativos o modelo errou em 41% (19% a mais do que o outro modelo). </p> <h3>CONSIDERAÇÕES FINAIS</h3> <p> Usar um modelo de algoritmo para prever e/ou classificar, contribui em muito para um negócio, mas para que atinga bons resultados, à toda uma complexidade por trás. É preciso analisar com atenção os dados e usar boas ferramentas antes de partirmos para criação de um modelo e elas fazem toda a diferença. Essa etapa pode ser longa e cansativa mas vale por todo o esforço. Neste projeto pude ver isso na prática, a análise foi bem extensa e utilizei ferramentas que auxiliaram para que o modelo pudesse ser treinado e testado da melhor maneira, e ainda assim, alguns dos métodos utilizados nem sempre trazem resultados tão eficientes quanto precisamos. Finalizo enfatizando que todo modelo pode ser melhorado, melhor parametrizado e avaliado depois que os dados estejam preparados. Te convido para entrar neste <a href="https://bit.ly/2HOrJDo">link</a> e ver o notebook completo desta análise. </p> </div> </div>  <footer id="footer"> <div class="inner"> <section> <h2>Contact me</h2> <ul class="icons"> <li> <a href="https://www.linkedin.com/in/jdomeneghini" target="_blank" class="brands icon style2"><i class="fa-linkedin fab"></i> <span class="label">Linkedin</span></a> </li> <li> <a href="https://jdomeneghini.medium.com" class="brands icon style2" target="_blank"><i class="fa-medium-m fab"></i><span class="label">Medium</span></a> </li> <li> <a href="https://github.com/jdomeneghini" target="_blank" class="brands icon style2"><i class="fa-github fab"></i><span class="label">GitHub</span></a> </li> <li> <a href="mailto:jessicadomeneghini@gmail.com" class="icon solid style2"><i class="fa-envelope fas"></i><span class="label">Email</span></a> </li> </ul> </section> </div> </footer> </div>  <script src="/js/util.8365f9b5.js"></script> <script src="/js/main.8e9eaf07.js"></script> </body></html>